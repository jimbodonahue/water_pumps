{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is my first attempt at exploring the data for the Redi 2025 summer Data Circle. The project is Pump it Up: Data Mining the Water Table, the information for which one can find [here](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/page/25/). All mistakes are my own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-28T09:49:45.328989Z",
     "iopub.status.busy": "2025-03-28T09:49:45.328366Z",
     "iopub.status.idle": "2025-03-28T09:49:48.215258Z",
     "shell.execute_reply": "2025-03-28T09:49:48.214148Z",
     "shell.execute_reply.started": "2025-03-28T09:49:45.328930Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import geopandas as gpd # geospatial data processing\n",
    "import matplotlib.pyplot as plt # standard plotting packages\n",
    "import seaborn as sns\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# I am running these on Kaggle, because my computer and I are fighting. Feel free to set your own path\n",
    "path = '~/coding/water_pumps/Data/'\n",
    "# Reading the files\n",
    "train = pd.read_csv(path+'train.csv')\n",
    "test = pd.read_csv(path+'test.csv')\n",
    "labels = pd.read_csv(path+'train_labels.csv')\n",
    "# final submission file to be added later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial exploring, missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T09:49:48.216980Z",
     "iopub.status.busy": "2025-03-28T09:49:48.216670Z",
     "iopub.status.idle": "2025-03-28T09:49:48.310776Z",
     "shell.execute_reply": "2025-03-28T09:49:48.309524Z",
     "shell.execute_reply.started": "2025-03-28T09:49:48.216954Z"
    }
   },
   "outputs": [],
   "source": [
    "# Format number display, show all columns\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_columns', 55)\n",
    "print(\"Size = \",train.shape)\n",
    "print(\"Labels = \", labels.head())\n",
    "print(train.head(10))\n",
    "# print(train.info())\n",
    "print(train.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First impressions\n",
    "The qualitative data seem to repeat, particularly in variables ending with `_group`. This means that we have less data than I originally though. However, the geo data should allow us to include external data on weather, population density, economic activity, etc. Some missing values also seem to be coded as 0 (average year is *not* 1300).\n",
    "\n",
    "From a data transformation standpoint, there are few quantitative variables. Really, only `amount_tsh` (available amount), `gps_height`, `population`, and `construction_year` jump out to me, with possible help from `num_private` (although it seems to be mostly 0). Hopefully the categorical data will prove useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T09:49:48.313071Z",
     "iopub.status.busy": "2025-03-28T09:49:48.312687Z",
     "iopub.status.idle": "2025-03-28T09:49:48.550224Z",
     "shell.execute_reply": "2025-03-28T09:49:48.549130Z",
     "shell.execute_reply.started": "2025-03-28T09:49:48.313024Z"
    }
   },
   "outputs": [],
   "source": [
    "# regular missing values\n",
    "nan_first = train.isnull().sum().sort_values(ascending=False)*100/len(train)\n",
    "print(\"~~~ Percent missing values: \\n\", nan_first.map(\"{:,.2f}%\".format))\n",
    "print(\"~~~ Unique values:\\n\",train.nunique().sort_values(ascending=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T09:49:48.552258Z",
     "iopub.status.busy": "2025-03-28T09:49:48.551895Z",
     "iopub.status.idle": "2025-03-28T09:49:48.675137Z",
     "shell.execute_reply": "2025-03-28T09:49:48.673917Z",
     "shell.execute_reply.started": "2025-03-28T09:49:48.552218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting 0 to NaN in most numerical variables\n",
    "train['amount_tsh'] = train['amount_tsh'].replace(0, np.NaN)\n",
    "train['gps_height'] = train['gps_height'].replace(0, np.NaN)\n",
    "train['longitude'] = train['longitude'].replace(0, np.NaN)\n",
    "train['latitude'] = train['latitude'].where(train['latitude'] < -0.5, np.NaN) # too close to the equator\n",
    "# train['population'] = train['population'].replace(0, np.NaN)  ## I worry here that 0 may be true 0, making a histogram\n",
    "train['construction_year'] = train['construction_year'].replace(0, np.NaN) \n",
    "# num_private also ignored because I don't know what it means yet\n",
    "# print again\n",
    "nan_fixed = train.isnull().sum().sort_values(ascending=False)*100/len(train)\n",
    "diffs = (nan_fixed - nan_first)\n",
    "print(\"~~~ Differences: \\n\", diffs[diffs>0].map(\"{:,.1f}%\".format)) \n",
    "print(\"~~~ New percent missing values: \\n\",nan_fixed[nan_fixed>0].map(\"{:,.3f}%\".format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values summary\n",
    "Missing values are significant, particularly in `amount_tsh` *the total static head* (amount water available to waterpoint). I'm less worried about the half missing scheme names, more about the third construction year. GPS height we can probably get from the geo data. After the initial analysis, we're going to figure out if any of these are missing not at random.\n",
    "\n",
    "Also, after realizing that no latitude values were set as 0, I used -0.5 as a cutoff, which matches the number of changed cells as the longitude values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T09:49:48.676605Z",
     "iopub.status.busy": "2025-03-28T09:49:48.676298Z",
     "iopub.status.idle": "2025-03-28T09:49:48.837777Z",
     "shell.execute_reply": "2025-03-28T09:49:48.836139Z",
     "shell.execute_reply.started": "2025-03-28T09:49:48.676578Z"
    }
   },
   "outputs": [],
   "source": [
    "# Showing unique values for selected variables, probably too many but hey, pixles are cheap\n",
    "temp = train[['quantity','quantity_group','management','scheme_management','management_group','water_quality','quality_group','waterpoint_type','waterpoint_type_group','payment_type','payment','basin','source','source_class','source_type','extraction_type','extraction_type_class','extraction_type_group','region','region_code','public_meeting','permit']]\n",
    "for col in temp.columns:\n",
    "    print(\"~~~~~~~~~~~~~~~~\")\n",
    "    print(temp[col].value_counts().map(\"{:,.0f}\".format).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T12:26:05.938365Z",
     "iopub.status.busy": "2025-03-27T12:26:05.938003Z",
     "iopub.status.idle": "2025-03-27T12:26:05.951759Z",
     "shell.execute_reply": "2025-03-27T12:26:05.950276Z",
     "shell.execute_reply.started": "2025-03-27T12:26:05.938339Z"
    }
   },
   "source": [
    "## Unique values observations\n",
    "* `quantity` and `quantity_group` have the same number of observations, probably can drop one\n",
    "* `management` has more info than `management_group`, but still 40k observations for vwc. `scheme_management` seems not to add much, plus has more missing values. Make a dummy variable `vwc` and drop the rest?\n",
    "* `water_quality` is also mostly the same, quality group very similar\n",
    "* `waterpoint_type` brings more, but `waterpoint_type_group` is just that, with the two communal standpipes added\n",
    "* `payment` looks promising, with the respective `_type` simply being the same counts. Drop (unless counts are the same but obs are different)\n",
    "* `basin`, `region` could feed into our geospatial analysis. I actually like `basin` better because it correlates more closely with the weather aspect and would be more useful in a model with rainfall, for example.\n",
    "* `source` could also help with a geospatial model using weather. For the overall model, `source_class` is more succinct, binary plus 278 \"unknown\" (missing values). `source_type` adds other & unknown, hand & machine dtw (down the well?). river & lake.\n",
    "* The extraction variables are half based on gravity. `extraction_type_class` is the most general, but I think that deciding this will require some domain-specific research.\n",
    "* We know from earlier that `region_code` has 27 unique values, `region` has 21, and `district_code` 20. This is more granular than the 9 basins, but seems inconsistent. Other geographical options are `lga` (125 unique values), `ward (2092), and subvillage (19287(!)). Decisions, decisions...\n",
    "* `public_meeting` and `permit` are binary. The former is mostly true, might not be useful. But only about 2/3 of pumps have permits, which may be helpful (although 5% missing values). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting into Spatial Analysis\n",
    "Here I'm out of my element, happy for any tips at all. First, we'll try a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T09:49:48.839467Z",
     "iopub.status.busy": "2025-03-28T09:49:48.839058Z"
    }
   },
   "outputs": [],
   "source": [
    "# First, adding the status to the data frame (no leakage because they told us to graph like this?)\n",
    "train = pd.merge(train, labels, on='id')\n",
    "# load into geo df\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    train, geometry=gpd.points_from_xy(train.longitude, train.latitude), crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# import the necessary packages\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    " \n",
    "#border.to_crs(epsg=27701).plot(ax=ax, color='lightgrey') ## figure out .to_crs meaning??\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "tanz = world.loc[world['name'] == 'Tanzania']\n",
    "border = tanz['geometry']\n",
    "gdf.border = border\n",
    "# gdf = gdf.set_index('region_code')\n",
    "\n",
    "# create an Axes object and plot the map\n",
    "# fig, ax = plt.subplots(figsize=(8,8))\n",
    "# gdf.plot(ax=ax, color='purple', alpha=0.1)#, cmap='PRGn')\n",
    "cmap, norm = mcolors.from_levels_and_colors([0, 2, 5, 6], ['red', 'orange', 'blue'])\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "border.to_crs(epsg=4326).plot(ax=ax, color='lightgrey', edgecolor='k')\n",
    "gdf.plot(column='status_group', cmap=cmap, marker='*', markersize=3, ax=ax, alpha=0.2)\n",
    "\n",
    "ax.set_title('Water Pumps Nationwide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('sample1_2.gpkg')                                \n",
    "cursor = conn.cursor()\n",
    "# not working\n",
    "cursor.execute(\"SELECT Shape FROM counties LIMIT 1;\")\n",
    "result = cursor.fetchone()[0]\n",
    "# also failed: gpd.read_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapp = gpd.read_file(\"~/coding/water_pumps/shape.shp\")\n",
    "print(shapp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shapp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import mapclassify\n",
    "shapp.explore()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6929771,
     "sourceId": 11114340,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
