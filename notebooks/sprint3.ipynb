{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f70224-f62d-4022-b3cb-91452db78260",
   "metadata": {},
   "source": [
    "### Comparation of 3 base models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb71c29a-1733-4dd9-9c4f-a084ac8ebe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "387d865d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cool\n"
     ]
    }
   ],
   "source": [
    "# create a class that we can pass to the pipeline\n",
    "class DataCleaner:\n",
    "\n",
    "    def __init__(self):\n",
    "        print('Cleaning ...')\n",
    "\n",
    "    def clean_numeric(self, df):\n",
    "        #\n",
    "        # Construction year\n",
    "        df['construction_year'] = df['construction_year'].replace(0, np.nan)\n",
    "        #Impute using region + installer\n",
    "        df['construction_year'] = df.groupby(['region', 'installer'])['construction_year'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        #Impute using region only (for rows still missing)\n",
    "        df['construction_year'] = df.groupby('region')['construction_year'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        #Use recorded year - 13\n",
    "        df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
    "        df['recorded_year'] = df['date_recorded'].dt.year\n",
    "        df['construction_year'] = df['construction_year'].fillna(df['recorded_year'] - 13)\n",
    "        #\n",
    "        # gps_height\n",
    "        df['gps_height'] = df['gps_height'].apply(lambda x: np.nan if x <= 0 else x)\n",
    "        # Fill using median per lga\n",
    "        df['gps_height'] = df.groupby('lga')['gps_height'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        # Fill any still missing using region median\n",
    "        df['gps_height'] = df.groupby('region')['gps_height'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        #\n",
    "        #location\n",
    "        df['longitude'] = df['longitude'].replace(0, np.nan)\n",
    "        df['latitude'] = df['latitude'].where(df['latitude'] < -0.5, np.nan) # too close to the equator\n",
    "        for i in ['latitude','longitude']:\n",
    "            df[i] = df.groupby('lga')[i].transform(lambda x: x.fillna(x.median))\n",
    "            df[i] = df.groupby('region')[i].transform(lambda x: x.fillna(x.median))\n",
    "        df.longitude = pd.to_numeric(df.longitude, errors='coerce')\n",
    "        df.latitude = pd.to_numeric(df.latitude, errors='coerce')\n",
    "        #\n",
    "        # population\n",
    "        # Fill population using median by district_code\n",
    "        df['population'] = df.groupby('lga')['population'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        # Fill any still missing with median by region, then overall median\n",
    "        df['population'] = df.groupby('region')['population'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        df['population'] = df['population'].fillna(df.population.median)\n",
    "        # Bin the outcome, see how it behaves\n",
    "        df['population'] = pd.cut(df['population'], [-1,1,25,90,160,260,9999999], labels=[0,0.2,0.3,0.4,0.6,1])\n",
    "        df['population'] = df['population'].astype(float)\n",
    "        #\n",
    "        # amount_tsh\n",
    "        df['amount_tsh'] = df['amount_tsh'].apply(lambda x: min(x, 15000))\n",
    "        return df\n",
    "\n",
    "    def clean_categorical(self, df):\n",
    "            ### Encode categorical variables\n",
    "        # Encode 'quantity' (and typo fix: 'insufficent' -> 'insufficient')\n",
    "        df['quantity'] = df['quantity'].replace({\n",
    "            'enough': 1,\n",
    "            'seasonal': 0.6,\n",
    "            'insufficient': 0.4,\n",
    "            'dry': 0,\n",
    "            'unknown': 0\n",
    "        })\n",
    "        df.quantity = pd.to_numeric(df.quantity, errors='coerce')\n",
    "\n",
    "        # Encode 'water_quality' as binary: good = 1, else 0\n",
    "        df['water_quality'] = np.where(df['water_quality'] == 'soft', 1, 0)\n",
    "        # Encode 'waterpoint_type' (1 = preferred type, 0 = everything else)\n",
    "        preferred_waterpoint = ['hand pump', 'communal standpipe']\n",
    "        df['waterpoint_type'] = df['waterpoint_type'].apply(lambda x: 1 if x in preferred_waterpoint else 0)\n",
    "        # Encode 'permit' as binary: True = 1, False, missing = 0\n",
    "        df['permit'] = np.where(df['permit'] == 'True', 1, 0)\n",
    "        # Encode 'payment' as binary: never pay = 0, else = 1\n",
    "        df['payment'] = np.where(df['payment'] == 'never pay', 0, 1)\n",
    "        # Encode 'source' (1 = preferred sources, 0 = everything else)\n",
    "        preferred_sources = ['spring', 'river', 'rainwater harvesting']\n",
    "        df['source'] = df['source'].apply(lambda x: 1 if x in preferred_sources else 0)\n",
    "        # Encode 'payment' as binary: never pay = 0, else = 1\n",
    "        df['extraction_type_class'] = np.where(df['extraction_type_class'] == 'gravity', 0, 1)\n",
    "        # Encode 'scheme_management' (1 = VWC, others 0)\n",
    "        df['scheme_management'] = np.where(df['scheme_management'] == 'VWC', 0, 1)\n",
    "        # one hot encoder for basin \n",
    "        df = pd.get_dummies(data=df, columns=['basin'], drop_first=True, dtype=int)\n",
    "        return df\n",
    "\n",
    "    def selection(self, df):\n",
    "         #  Drop other columns and only keep these:\n",
    "        # df_small = df[['amount_tsh',\n",
    "        #     'gps_height',\n",
    "        #     'population',\n",
    "        #     'construction_year',\n",
    "        #     'extraction_type_class',\n",
    "        #     'payment',\n",
    "        #     'water_quality',\n",
    "        #     'quantity',\n",
    "        #     'source',\n",
    "        #     'waterpoint_type'\n",
    "        #    ]]\n",
    "        #  #  Drop other columns and only keep these:\n",
    "        # df_medium = df[['amount_tsh',\n",
    "        #          'gps_height',\n",
    "        #          'longitude',\n",
    "        #          'latitude',\n",
    "        #          'population',\n",
    "        #          'construction_year',\n",
    "        #          'extraction_type_class',\n",
    "        #          'payment',\n",
    "        #         'water_quality',\n",
    "        #         'quantity',\n",
    "        #         'source',\n",
    "        #         'waterpoint_type',, 'basin_Lake Nyasa', 'basin_Lake Rukwa',\n",
    "        #         'basin_Lake Tanganyika', 'basin_Lake Victoria', 'basin_Pangani',\n",
    "        #         'basin_Rufiji', 'basin_Ruvuma / Southern Coast', 'basin_Wami / Ruvu'\n",
    "        #         'scheme_management'\n",
    "        #        ]]\n",
    "        df = df[['amount_tsh',\n",
    "                 'gps_height',\n",
    "                 'longitude',\n",
    "                 'latitude',\n",
    "                 'population',\n",
    "                 'construction_year',\n",
    "                 'extraction_type_class',\n",
    "                 'payment',\n",
    "                'water_quality',\n",
    "                'quantity',\n",
    "                'source',\n",
    "                'waterpoint_type', \n",
    "                'scheme_management', 'basin_Lake Nyasa', 'basin_Lake Rukwa',\n",
    "                'basin_Lake Tanganyika', 'basin_Lake Victoria', 'basin_Pangani',\n",
    "                'basin_Rufiji', 'basin_Ruvuma / Southern Coast', 'basin_Wami / Ruvu'\n",
    "               ]]\n",
    "#        df['tshXpayment'] = df.amount_tsh * df.payment\n",
    "#        df['extractXsource'] = df.extraction_type_class * df.source\n",
    "#        df['popXtsh'] = df.population * df.amount_tsh\n",
    "#        df['popXquant'] = df.population * df.quantity\n",
    "#        df['popXsource'] = df.population * df.source\n",
    "#        df['extractXheight'] = df.extraction_type_class * df.gps_height\n",
    "#        df['typeXsource'] = df.waterpoint_type * df.source\n",
    "#        df['typeXyear'] = df.waterpoint_type * df.construction_year\n",
    "#        df['yearXpop'] = df.construction_year * df.population\n",
    "#        df['quantXsource'] = df.quantity * df.source\n",
    "        df['yearsq'] = np.sqrt(df.construction_year + 1)\n",
    "        df_large = df\n",
    "\n",
    "        return df#_small, df_medium, df_large\n",
    "\n",
    "    def clean_data(self, df): \n",
    "        df = self.clean_numeric(df) \n",
    "        df = self.clean_categorical(df)\n",
    "        df = self.selection(df)\n",
    "        return df\n",
    "        \n",
    "print('cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bd38826a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11469/702393985.py:40: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[i] = df.groupby('region')[i].transform(lambda x: x.fillna(x.median))\n",
      "/tmp/ipykernel_11469/702393985.py:40: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[i] = df.groupby('region')[i].transform(lambda x: x.fillna(x.median))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 22 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   amount_tsh                     59400 non-null  float64\n",
      " 1   gps_height                     47285 non-null  float64\n",
      " 2   longitude                      57588 non-null  float64\n",
      " 3   latitude                       57588 non-null  float64\n",
      " 4   population                     59400 non-null  float64\n",
      " 5   construction_year              59400 non-null  float64\n",
      " 6   extraction_type_class          59400 non-null  int64  \n",
      " 7   payment                        59400 non-null  int64  \n",
      " 8   water_quality                  59400 non-null  int64  \n",
      " 9   quantity                       59400 non-null  float64\n",
      " 10  source                         59400 non-null  int64  \n",
      " 11  waterpoint_type                59400 non-null  int64  \n",
      " 12  scheme_management              59400 non-null  int64  \n",
      " 13  basin_Lake Nyasa               59400 non-null  int64  \n",
      " 14  basin_Lake Rukwa               59400 non-null  int64  \n",
      " 15  basin_Lake Tanganyika          59400 non-null  int64  \n",
      " 16  basin_Lake Victoria            59400 non-null  int64  \n",
      " 17  basin_Pangani                  59400 non-null  int64  \n",
      " 18  basin_Rufiji                   59400 non-null  int64  \n",
      " 19  basin_Ruvuma / Southern Coast  59400 non-null  int64  \n",
      " 20  basin_Wami / Ruvu              59400 non-null  int64  \n",
      " 21  yearsq                         59400 non-null  float64\n",
      "dtypes: float64(8), int64(14)\n",
      "memory usage: 10.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Using the cleaning function on the original training data\n",
    "\n",
    "cleaner = DataCleaner()\n",
    "X = cleaner.clean_data(train)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4e7cc17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 22 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   amount_tsh                     59400 non-null  float64\n",
      " 1   gps_height                     59400 non-null  object \n",
      " 2   longitude                      59400 non-null  object \n",
      " 3   latitude                       59400 non-null  object \n",
      " 4   population                     59400 non-null  float64\n",
      " 5   construction_year              59400 non-null  float64\n",
      " 6   extraction_type_class          59400 non-null  int64  \n",
      " 7   payment                        59400 non-null  int64  \n",
      " 8   water_quality                  59400 non-null  int64  \n",
      " 9   quantity                       59400 non-null  float64\n",
      " 10  source                         59400 non-null  int64  \n",
      " 11  waterpoint_type                59400 non-null  int64  \n",
      " 12  scheme_management              59400 non-null  int64  \n",
      " 13  basin_Lake Nyasa               59400 non-null  int64  \n",
      " 14  basin_Lake Rukwa               59400 non-null  int64  \n",
      " 15  basin_Lake Tanganyika          59400 non-null  int64  \n",
      " 16  basin_Lake Victoria            59400 non-null  int64  \n",
      " 17  basin_Pangani                  59400 non-null  int64  \n",
      " 18  basin_Rufiji                   59400 non-null  int64  \n",
      " 19  basin_Ruvuma / Southern Coast  59400 non-null  int64  \n",
      " 20  basin_Wami / Ruvu              59400 non-null  int64  \n",
      " 21  yearsq                         59400 non-null  float64\n",
      "dtypes: float64(5), int64(14), object(3)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import power_transform\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pt', PowerTransformer())\n",
    "    ('logreg', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "from sklearn import svm, neighbors, tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a33cda0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Lake Nyasa', 'Lake Rukwa', 'Lake Tanganyika', 'Lake Victoria',\n",
       "       'Pangani', 'Rufiji', 'Ruvuma / Southern Coast', 'Wami / Ruvu'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a271daec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394d355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ae8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d5bec11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construction_year      int64\n",
      "date_recorded         object\n",
      "gps_height             int64\n",
      "longitude            float64\n",
      "latitude             float64\n",
      "lga                   object\n",
      "region                object\n",
      "dtype: object\n",
      "~~~~~~~~~\n",
      " construction_year      int64\n",
      "date_recorded         object\n",
      "gps_height           float64\n",
      "longitude             object\n",
      "latitude              object\n",
      "lga                   object\n",
      "region                object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11469/1791510720.py:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[i] = df.groupby('region')[i].transform(lambda x: x.fillna(x.median))\n",
      "/tmp/ipykernel_11469/1791510720.py:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[i] = df.groupby('region')[i].transform(lambda x: x.fillna(x.median))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(os.path.join(data_path, 'train.csv')) \n",
    "df = df[['construction_year','date_recorded','gps_height','longitude','latitude','lga','region']]\n",
    "print(df.dtypes)\n",
    "\n",
    "\n",
    "# gps_height\n",
    "df['gps_height'] = df['gps_height'].apply(lambda x: np.nan if x <= 0 else x)\n",
    "# Fill using median per lga\n",
    "df['gps_height'] = df.groupby('lga')['gps_height'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "# Fill any still missing using region median\n",
    "df['gps_height'] = df.groupby('region')['gps_height'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "#\n",
    "#location\n",
    "df['longitude'] = df['longitude'].replace(0, np.nan)\n",
    "df['latitude'] = df['latitude'].where(df['latitude'] < -0.5, np.nan) # too close to the equator\n",
    "for i in ['latitude','longitude']:\n",
    "    df[i] = df.groupby('lga')[i].transform(lambda x: x.fillna(x.median))\n",
    "    df[i] = df.groupby('region')[i].transform(lambda x: x.fillna(x.median))\n",
    "#df.longitude = pd.to_numeric(df.longitude, errors='coerce')\n",
    "#df.latitude = pd.to_numeric(df.latitude, errors='coerce')\n",
    "#\n",
    "print('~~~~~~~~~\\n',df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e8d6e6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt.fit(data):  PowerTransformer()\n",
      "pt.lambdas_:  [ 0.81761727 -0.05022969]\n",
      "pt.transform(data)  [[-1.41108034 -1.38481521]\n",
      " [-0.36251621 -0.25831859]\n",
      " [ 0.49653431  0.24467264]\n",
      " [ 1.27706224  1.39846116]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "pt = PowerTransformer()\n",
    "pt.lambdas_ = {0:1,1:0}\n",
    "data = [[-1, 0], [1, 2], [3, 4], [5,16]]\n",
    "print('pt.fit(data): ', pt.fit(data))\n",
    "print('pt.lambdas_: ', pt.lambdas_)\n",
    "print('pt.transform(data) ', pt.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb7792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (water_pumps)",
   "language": "python",
   "name": "water_pumps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
