{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f70224-f62d-4022-b3cb-91452db78260",
   "metadata": {},
   "source": [
    "### Comparation of 3 base models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb71c29a-1733-4dd9-9c4f-a084ac8ebe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "387d865d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready for piping\n"
     ]
    }
   ],
   "source": [
    "# run this cell to initiate the function, then the pipeline *should* run smoothly\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def clean_func(df):\n",
    "    #\n",
    "    # Construction year\n",
    "    df['construction_year'] = df['construction_year'].replace(0, np.nan)\n",
    "    #Impute using region + installer\n",
    "    df['construction_year'] = df.groupby(['region', 'installer'])['construction_year'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "    #Impute using region only (for rows still missing)\n",
    "    df['construction_year'] = df.groupby('region')['construction_year'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "    #Use recorded year - 13\n",
    "    df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
    "    df['recorded_year'] = df['date_recorded'].dt.year\n",
    "    df['construction_year'] = df['construction_year'].fillna(df['recorded_year'] - 13)\n",
    "    #\n",
    "    # gps_height \n",
    "    df['gps_height'] = df['gps_height'].apply(lambda x: np.nan if x <= 0 else x)\n",
    "    # Fill using median per lga\n",
    "    df['gps_height'] = df.groupby('lga')['gps_height'].fillna(df['gps_height'].median())\n",
    "    # Fill any still missing using region median\n",
    "    df['gps_height'] = df.groupby(['region'])['gps_height'].fillna(df['gps_height'].median())\n",
    "    # Longitude and latitude\n",
    "    df['longitude'] = df['longitude'].replace(0, np.nan)\n",
    "    df['latitude'] = df['latitude'].where(df['latitude'] < -0.5, np.nan) # too close to the equator\n",
    "    for i in ['latitude','longitude']: # loop to fill by lga, region\n",
    "        df[i] = df.groupby(['lga'])[i].fillna(df[i].median())\n",
    "        df[i] = df.groupby(['region'])[i].fillna(df[i].median())\n",
    "    # population\n",
    "    # Fill population using median by district_code\n",
    "    df['population'] = df.groupby('lga')['population'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "    # Fill any still missing with median by region, then overall median\n",
    "    df['population'] = df.groupby('region')['population'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "    df['population'] = df['population'].fillna(df.population.median)\n",
    "    # Bin the outcome, see how it behaves\n",
    "    df['population'] = pd.cut(df['population'], [-1,1,25,90,160,260,9999999], labels=[0,0.2,0.3,0.4,0.6,1])\n",
    "    df['population'] = df['population'].astype(float)\n",
    "    #\n",
    "    # amount_tsh\n",
    "    df['amount_tsh'] = df['amount_tsh'].apply(lambda x: min(x, 15000))\n",
    "    df['amount_tsh'] = df['amount_tsh'].apply(lambda x: np.power(x,0.3))\n",
    "        ### Encode categorical variables\n",
    "    # Encode 'quantity' (and typo fix: 'insufficent' -> 'insufficient')\n",
    "    df['quantity'] = df['quantity'].replace({\n",
    "        'enough': 1,\n",
    "        'seasonal': 0.6,\n",
    "        'insufficient': 0.4,\n",
    "        'dry': 0,\n",
    "        'unknown': 0\n",
    "    })\n",
    "    df.quantity = pd.to_numeric(df.quantity, errors='coerce')\n",
    "\n",
    "    # Encode 'water_quality' as binary: good = 1, else 0\n",
    "    df['water_quality'] = np.where(df['water_quality'] == 'soft', 1, 0)\n",
    "    # Encode 'waterpoint_type' (1 = preferred type, 0 = everything else)\n",
    "    preferred_waterpoint = ['communal standpipe multiple', 'communal standpipe']\n",
    "    df['waterpoint_type'] = df['waterpoint_type'].apply(lambda x: 1 if x in preferred_waterpoint else 0)\n",
    "    # Encode 'permit' as binary: True = 1, False, missing = 0\n",
    "    df['permit'] = np.where(df['permit'] == 'True', 1, 0)\n",
    "    # Encode 'payment' as binary: never pay = 0, else = 1\n",
    "    df['payment'] = np.where(df['payment'] == 'never pay', 0, 1)\n",
    "    # Encode 'source' (1 = preferred sources, 0 = everything else)\n",
    "    preferred_sources = ['spring', 'river', 'rainwater harvesting']\n",
    "    df['source'] = df['source'].apply(lambda x: 1 if x in preferred_sources else 0)\n",
    "    # Encode 'payment' as binary: never pay = 0, else = 1\n",
    "    df['extraction_type_class'] = np.where(df['extraction_type_class'] == 'gravity', 0, 1)\n",
    "    # Encode 'scheme_management' (1 = VWC, others 0)\n",
    "    df['scheme_management'] = np.where(df['scheme_management'] == 'VWC', 0, 1)\n",
    "    # one hot encoder for basin \n",
    "    df = pd.get_dummies(data=df, columns=['basin'], drop_first=True, dtype=int)\n",
    "    ### Select what's good\n",
    "     #  Drop other columns and only keep these:\n",
    "    # df_small = df[['amount_tsh',\n",
    "    #     'gps_height',\n",
    "    #     'population',\n",
    "    #     'construction_year',\n",
    "    #     'extraction_type_class',\n",
    "    #     'payment',\n",
    "    #     'water_quality',\n",
    "    #     'quantity',\n",
    "    #     'source',\n",
    "    #     'waterpoint_type'\n",
    "    #    ]]\n",
    "    #  #  Drop other columns and only keep these:\n",
    "    # df_medium = df[['amount_tsh',\n",
    "    #          'gps_height',\n",
    "    #          'longitude',\n",
    "    #          'latitude',\n",
    "    #          'population',\n",
    "    #          'construction_year',\n",
    "    #          'extraction_type_class',\n",
    "    #          'payment',\n",
    "    #         'water_quality',\n",
    "    #         'quantity',\n",
    "    #         'source',\n",
    "    #         'waterpoint_type',, 'basin_Lake Nyasa', 'basin_Lake Rukwa',\n",
    "    #         'basin_Lake Tanganyika', 'basin_Lake Victoria', 'basin_Pangani',\n",
    "    #         'basin_Rufiji', 'basin_Ruvuma / Southern Coast', 'basin_Wami / Ruvu'\n",
    "    #         'scheme_management'\n",
    "    #        ]]\n",
    "    df = df[['amount_tsh',\n",
    "             'gps_height',\n",
    "             'longitude',\n",
    "             'latitude',\n",
    "             'population',\n",
    "             'construction_year',\n",
    "             'extraction_type_class',\n",
    "             'payment',\n",
    "            'water_quality',\n",
    "            'quantity',\n",
    "            'source',\n",
    "            'waterpoint_type', \n",
    "            'scheme_management', 'basin_Lake Nyasa', 'basin_Lake Rukwa',\n",
    "            'basin_Lake Tanganyika', 'basin_Lake Victoria', 'basin_Pangani',\n",
    "            'basin_Rufiji', 'basin_Ruvuma / Southern Coast', 'basin_Wami / Ruvu'\n",
    "           ]]\n",
    "    df['tshXpayment'] = df.amount_tsh * df.payment\n",
    "    df['extractXsource'] = df.extraction_type_class * df.source\n",
    "    df['popXtsh'] = df.population * df.amount_tsh\n",
    "    df['popXquant'] = df.population * df.quantity\n",
    "    df['popXsource'] = df.population * df.source\n",
    "    df['extractXheight'] = df.extraction_type_class * df.gps_height\n",
    "    df['typeXsource'] = df.waterpoint_type * df.source\n",
    "    df['typeXyear'] = df.waterpoint_type * df.construction_year\n",
    "    df['yearXpop'] = df.construction_year * df.population\n",
    "    df['quantXsource'] = df.quantity * df.source\n",
    "    df['yearsq'] = np.sqrt(df.construction_year + 1)\n",
    "    df_large = df\n",
    "    return df#_small, df_medium, df_large\n",
    "\n",
    "#def clean_data(self, df): \n",
    "#    df = self.clean_numeric(df) \n",
    "#    df = self.clean_categorical(df)\n",
    "#    df = self.selection(df)\n",
    "#    return df\n",
    "\n",
    "print('ready for piping')\n",
    "\n",
    "my_transformer = FunctionTransformer(clean_func)\n",
    "\n",
    "# then \n",
    "# pipeline = Pipeline([\n",
    "#     ('data_transformer', my_transformer), # this is how we clean the data\n",
    "# etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19d7d8e1-a419-4d11-976f-898317518139",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "data_path = os.path.join(parent_dir, 'data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7e226c8-2d73-4d88-8f09-634612434f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Mean of empty slice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fc0c4a1-bfa7-4d20-9d59-e24bfef80658",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_transformer = FunctionTransformer(clean_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ffaa981-33d4-46c9-990a-6b1c760df139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files\n",
    "train = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
    "labels = pd.read_csv(os.path.join(data_path, 'train_labels.csv'))\n",
    "\n",
    "# Try the function\n",
    "y = labels['status_group']  \n",
    "X = train.copy() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe6649ca-81e8-45cd-aa04-103e45a41b02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m      2\u001b[0m     X, \n\u001b[1;32m----> 3\u001b[0m     \u001b[43my\u001b[49m, \n\u001b[0;32m      4\u001b[0m     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.20\u001b[39m,\n\u001b[0;32m      5\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m      6\u001b[0m     stratify\u001b[38;5;241m=\u001b[39my\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5094fcc6-0cb1-4bf6-b19f-3f2acc611752",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m      2\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean\u001b[39m\u001b[38;5;124m'\u001b[39m, clean_transformer),\n\u001b[1;32m----> 3\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mDecisionTreeClassifier\u001b[49m(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[0;32m      4\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clean', clean_transformer),\n",
    "    ('clf', DecisionTreeClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd38826a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 32 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   amount_tsh                     59400 non-null  float64\n",
      " 1   gps_height                     59400 non-null  float64\n",
      " 2   longitude                      59400 non-null  float64\n",
      " 3   latitude                       59400 non-null  float64\n",
      " 4   population                     59400 non-null  float64\n",
      " 5   construction_year              59400 non-null  float64\n",
      " 6   extraction_type_class          59400 non-null  int64  \n",
      " 7   payment                        59400 non-null  int64  \n",
      " 8   water_quality                  59400 non-null  int64  \n",
      " 9   quantity                       59400 non-null  float64\n",
      " 10  source                         59400 non-null  int64  \n",
      " 11  waterpoint_type                59400 non-null  int64  \n",
      " 12  scheme_management              59400 non-null  int64  \n",
      " 13  basin_Lake Nyasa               59400 non-null  int64  \n",
      " 14  basin_Lake Rukwa               59400 non-null  int64  \n",
      " 15  basin_Lake Tanganyika          59400 non-null  int64  \n",
      " 16  basin_Lake Victoria            59400 non-null  int64  \n",
      " 17  basin_Pangani                  59400 non-null  int64  \n",
      " 18  basin_Rufiji                   59400 non-null  int64  \n",
      " 19  basin_Ruvuma / Southern Coast  59400 non-null  int64  \n",
      " 20  basin_Wami / Ruvu              59400 non-null  int64  \n",
      " 21  tshXpayment                    59400 non-null  float64\n",
      " 22  extractXsource                 59400 non-null  int64  \n",
      " 23  popXtsh                        59400 non-null  float64\n",
      " 24  popXquant                      59400 non-null  float64\n",
      " 25  popXsource                     59400 non-null  float64\n",
      " 26  extractXheight                 59400 non-null  float64\n",
      " 27  typeXsource                    59400 non-null  int64  \n",
      " 28  typeXyear                      59400 non-null  float64\n",
      " 29  yearXpop                       59400 non-null  float64\n",
      " 30  quantXsource                   59400 non-null  float64\n",
      " 31  yearsq                         59400 non-null  float64\n",
      "dtypes: float64(16), int64(16)\n",
      "memory usage: 14.5 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e7cc17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a33cda0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Lake Nyasa', 'Lake Rukwa', 'Lake Tanganyika', 'Lake Victoria',\n",
       "       'Pangani', 'Rufiji', 'Ruvuma / Southern Coast', 'Wami / Ruvu'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a271daec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394d355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ae8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bec11e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6e6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb7792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (water_pumps)",
   "language": "python",
   "name": "water_pumps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
