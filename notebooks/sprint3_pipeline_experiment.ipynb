{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f70224-f62d-4022-b3cb-91452db78260",
   "metadata": {},
   "source": [
    "## Data cleaning integrated with pipeline\n",
    "Because we've got a relatively small number of variables, we've been picky with using them. Below, I use define a class to clean the data. That didn't really work, so I put it in a function. Once that cell has been run, the `FunctionTransformer` can use it in the pipeline using `('data_transformer', my_transformer),`. I really wanted to get into variable importance, but I can't find the `coef_` method. I'll get more into it Monday. Probably.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fb71c29a-1733-4dd9-9c4f-a084ac8ebe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usual imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# data methods\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# misc\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "6ee74237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cool\n"
     ]
    }
   ],
   "source": [
    "# create a class that we can pass to the pipeline\n",
    "class DataCleaner:\n",
    "\n",
    "    def __init__(self):\n",
    "        print('Cleaning ...')\n",
    "\n",
    "    def clean_numeric(self, df):\n",
    "        #\n",
    "        # Construction year\n",
    "        df['construction_year'] = df['construction_year'].replace(0, np.nan)\n",
    "        #Impute using region + installer\n",
    "        df['construction_year'] = df.groupby(['region', 'installer'])['construction_year'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        #Impute using region only (for rows still missing)\n",
    "        df['construction_year'] = df.groupby('region')['construction_year'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        #Use recorded year - 13\n",
    "        df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
    "        df['recorded_year'] = df['date_recorded'].dt.year\n",
    "        df['construction_year'] = df['construction_year'].fillna(df['recorded_year'] - 13)\n",
    "        #\n",
    "        # gps_height\n",
    "        df['gps_height'] = df['gps_height'].apply(lambda x: np.nan if x <= 0 else x)\n",
    "        # Fill using median per lga\n",
    "        df['gps_height'] = df.groupby('lga')['gps_height'].fillna(df['gps_height'].median())\n",
    "        # Fill any still missing using region median\n",
    "        df['gps_height'] = df.groupby(['region'])['gps_height'].fillna(df['gps_height'].median())\n",
    "        # Longitude and latitude\n",
    "        df['longitude'] = df['longitude'].replace(0, np.nan)\n",
    "        df['latitude'] = df['latitude'].where(df['latitude'] < -0.5, np.nan) # too close to the equator\n",
    "        for i in ['latitude','longitude']: # loop to fill by lga, region\n",
    "            df[i] = df.groupby(['lga'])[i].fillna(df[i].median())\n",
    "            df[i] = df.groupby(['region'])[i].fillna(df[i].median())\n",
    "        #\n",
    "        # population\n",
    "        # Fill population using median by district_code\n",
    "        df['population'] = df.groupby('lga')['population'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        # Fill any still missing with median by region, then overall median\n",
    "        df['population'] = df.groupby('region')['population'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        df['population'] = df['population'].fillna(df.population.median)\n",
    "        # Bin the outcome, see how it behaves\n",
    "        df['population'] = pd.cut(df['population'], [-1,1,25,90,160,260,9999999], labels=[0,0.2,0.3,0.4,0.6,1])\n",
    "        df['population'] = df['population'].astype(float)\n",
    "        #\n",
    "        # amount_tsh\n",
    "        df['amount_tsh'] = df['amount_tsh'].apply(lambda x: min(x, 15000))\n",
    "        df['amount_tsh'] = df['amount_tsh'].apply(lambda x: np.power(x,0.3))\n",
    "        return df\n",
    "\n",
    "    def clean_categorical(self, df):\n",
    "            ### Encode categorical variables\n",
    "        # Encode 'quantity' (and typo fix: 'insufficent' -> 'insufficient')\n",
    "        df['quantity'] = df['quantity'].replace({\n",
    "            'enough': 1,\n",
    "            'seasonal': 0.6,\n",
    "            'insufficient': 0.4,\n",
    "            'dry': 0,\n",
    "            'unknown': 0\n",
    "        })\n",
    "        df.quantity = pd.to_numeric(df.quantity, errors='coerce')\n",
    "\n",
    "        # Encode 'water_quality' as binary: good = 1, else 0\n",
    "        df['water_quality'] = np.where(df['water_quality'] == 'soft', 1, 0)\n",
    "        # Encode 'waterpoint_type' (1 = preferred type, 0 = everything else)\n",
    "        preferred_waterpoint = ['communal standpipe multiple', 'communal standpipe']\n",
    "        df['waterpoint_type'] = df['waterpoint_type'].apply(lambda x: 1 if x in preferred_waterpoint else 0)\n",
    "        # Encode 'permit' as binary: True = 1, False, missing = 0\n",
    "        df['permit'] = np.where(df['permit'] == 'True', 1, 0)\n",
    "        # Encode 'payment' as binary: never pay = 0, else = 1\n",
    "        df['payment'] = np.where(df['payment'] == 'never pay', 0, 1)\n",
    "        # Encode 'source' (1 = preferred sources, 0 = everything else)\n",
    "        preferred_sources = ['spring', 'river', 'rainwater harvesting']\n",
    "        df['source'] = df['source'].apply(lambda x: 1 if x in preferred_sources else 0)\n",
    "        # Encode 'payment' as binary: never pay = 0, else = 1\n",
    "        df['extraction_type_class'] = np.where(df['extraction_type_class'] == 'gravity', 0, 1)\n",
    "        # Encode 'scheme_management' (1 = VWC, others 0)\n",
    "        df['scheme_management'] = np.where(df['scheme_management'] == 'VWC', 0, 1)\n",
    "        # one hot encoder for basin \n",
    "        df = pd.get_dummies(data=df, columns=['basin'], drop_first=True, dtype=int)\n",
    "        return df\n",
    "\n",
    "    def selection(self, df):\n",
    "         #  Drop other columns and only keep these:\n",
    "        # df_small = df[['amount_tsh',\n",
    "        #     'gps_height',\n",
    "        #     'population',\n",
    "        #     'construction_year',\n",
    "        #     'extraction_type_class',\n",
    "        #     'payment',\n",
    "        #     'water_quality',\n",
    "        #     'quantity',\n",
    "        #     'source',\n",
    "        #     'waterpoint_type'\n",
    "        #    ]]\n",
    "        #  #  Drop other columns and only keep these:\n",
    "        # df_medium = df[['amount_tsh',\n",
    "        #          'gps_height',\n",
    "        #          'longitude',\n",
    "        #          'latitude',\n",
    "        #          'population',\n",
    "        #          'construction_year',\n",
    "        #          'extraction_type_class',\n",
    "        #          'payment',\n",
    "        #         'water_quality',\n",
    "        #         'quantity',\n",
    "        #         'source',\n",
    "        #         'waterpoint_type',, 'basin_Lake Nyasa', 'basin_Lake Rukwa',\n",
    "        #         'basin_Lake Tanganyika', 'basin_Lake Victoria', 'basin_Pangani',\n",
    "        #         'basin_Rufiji', 'basin_Ruvuma / Southern Coast', 'basin_Wami / Ruvu'\n",
    "        #         'scheme_management'\n",
    "        #        ]]\n",
    "        df = df[['amount_tsh',\n",
    "                 'gps_height',\n",
    "                 'longitude',\n",
    "                 'latitude',\n",
    "                 'population',\n",
    "                 'construction_year',\n",
    "                 'extraction_type_class',\n",
    "                 'payment',\n",
    "                'water_quality',\n",
    "                'quantity',\n",
    "                'source',\n",
    "                'waterpoint_type', \n",
    "                'scheme_management', 'basin_Lake Nyasa', 'basin_Lake Rukwa',\n",
    "                'basin_Lake Tanganyika', 'basin_Lake Victoria', 'basin_Pangani',\n",
    "                'basin_Rufiji', 'basin_Ruvuma / Southern Coast', 'basin_Wami / Ruvu'\n",
    "               ]]\n",
    "        df['tshXpayment'] = df.amount_tsh * df.payment\n",
    "        df['extractXsource'] = df.extraction_type_class * df.source\n",
    "        df['popXtsh'] = df.population * df.amount_tsh\n",
    "        df['popXquant'] = df.population * df.quantity\n",
    "        df['popXsource'] = df.population * df.source\n",
    "        df['extractXheight'] = df.extraction_type_class * df.gps_height\n",
    "        df['typeXsource'] = df.waterpoint_type * df.source\n",
    "        df['typeXyear'] = df.waterpoint_type * df.construction_year\n",
    "        df['yearXpop'] = df.construction_year * df.population\n",
    "        df['quantXsource'] = df.quantity * df.source\n",
    "        df['yearsq'] = np.sqrt(df.construction_year + 1)\n",
    "        df_large = df\n",
    "\n",
    "        return df#_small, df_medium, df_large\n",
    "\n",
    "    def clean_data(self, df): \n",
    "        df = self.clean_numeric(df) \n",
    "        df = self.clean_categorical(df)\n",
    "        df = self.selection(df)\n",
    "        return df\n",
    "        \n",
    "print('cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d8d31b2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11469/2858631298.py:27: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  df['gps_height'] = df.groupby('lga')['gps_height'].fillna(df['gps_height'].median())\n",
      "/tmp/ipykernel_11469/2858631298.py:37: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  df[i] = df.groupby(['lga'])[i].fillna(df[i].median())\n",
      "/tmp/ipykernel_11469/2858631298.py:38: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  df[i] = df.groupby(['region'])[i].fillna(df[i].median())\n",
      "/tmp/ipykernel_11469/2858631298.py:37: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  df[i] = df.groupby(['lga'])[i].fillna(df[i].median())\n",
      "/tmp/ipykernel_11469/2858631298.py:38: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  df[i] = df.groupby(['region'])[i].fillna(df[i].median())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "amount_tsh                       0\n",
       "gps_height                       0\n",
       "longitude                        0\n",
       "latitude                         0\n",
       "population                       0\n",
       "construction_year                0\n",
       "extraction_type_class            0\n",
       "payment                          0\n",
       "water_quality                    0\n",
       "quantity                         0\n",
       "source                           0\n",
       "waterpoint_type                  0\n",
       "scheme_management                0\n",
       "basin_Lake Nyasa                 0\n",
       "basin_Lake Rukwa                 0\n",
       "basin_Lake Tanganyika            0\n",
       "basin_Lake Victoria              0\n",
       "basin_Pangani                    0\n",
       "basin_Rufiji                     0\n",
       "basin_Ruvuma / Southern Coast    0\n",
       "basin_Wami / Ruvu                0\n",
       "tshXpayment                      0\n",
       "extractXsource                   0\n",
       "popXtsh                          0\n",
       "popXquant                        0\n",
       "popXsource                       0\n",
       "extractXheight                   0\n",
       "typeXsource                      0\n",
       "typeXyear                        0\n",
       "yearXpop                         0\n",
       "quantXsource                     0\n",
       "yearsq                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the cleaning function on the original training data\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "data_path = os.path.join(parent_dir, 'data')\n",
    "out_path = os.path.join(parent_dir, 'outputs')\n",
    "\n",
    "# Read the files\n",
    "train = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
    "labels = pd.read_csv(os.path.join(data_path, 'train_labels.csv')) \n",
    "\n",
    "# Try the function\n",
    "cleaner = DataCleaner()\n",
    "X = cleaner.clean_data(train)\n",
    "\n",
    "X.isna().sum() # returns all floats and integers, which makes me happier than it should\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "97e57ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>37115.131768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18519.75</td>\n",
       "      <td>37061.5</td>\n",
       "      <td>55656.5</td>\n",
       "      <td>74247.0</td>\n",
       "      <td>21453.128371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount_tsh</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>1.705425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.456456</td>\n",
       "      <td>17.898943</td>\n",
       "      <td>3.16077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_recorded</th>\n",
       "      <td>59400</td>\n",
       "      <td>2012-03-29 09:11:33.818181888</td>\n",
       "      <td>2002-10-14 00:00:00</td>\n",
       "      <td>2011-04-01 00:00:00</td>\n",
       "      <td>2012-10-10 00:00:00</td>\n",
       "      <td>2013-02-09 00:00:00</td>\n",
       "      <td>2013-12-03 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gps_height</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>1109.69633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>1319.25</td>\n",
       "      <td>2770.0</td>\n",
       "      <td>471.186468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>35.145285</td>\n",
       "      <td>29.607122</td>\n",
       "      <td>33.354079</td>\n",
       "      <td>35.005943</td>\n",
       "      <td>37.178387</td>\n",
       "      <td>40.345193</td>\n",
       "      <td>2.567468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>-5.863826</td>\n",
       "      <td>-11.64944</td>\n",
       "      <td>-8.540621</td>\n",
       "      <td>-5.172704</td>\n",
       "      <td>-3.398151</td>\n",
       "      <td>-0.998464</td>\n",
       "      <td>2.769401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_private</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>0.474141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1776.0</td>\n",
       "      <td>12.23623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_code</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>15.297003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>17.587406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district_code</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>5.629747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.633649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>0.333443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.38698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scheme_management</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>0.380589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.485536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>permit</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construction_year</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>1997.552921</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>9.993723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_class</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>0.549158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.497582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>0.573266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.494607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_quality</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>0.855522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.351577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>0.701475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.363207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>0.487003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterpoint_type</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>0.582912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.493082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recorded_year</th>\n",
       "      <td>59400.0</td>\n",
       "      <td>2011.921667</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0.958758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count                           mean  \\\n",
       "id                     59400.0                   37115.131768   \n",
       "amount_tsh             59400.0                       1.705425   \n",
       "date_recorded            59400  2012-03-29 09:11:33.818181888   \n",
       "gps_height             59400.0                     1109.69633   \n",
       "longitude              59400.0                      35.145285   \n",
       "latitude               59400.0                      -5.863826   \n",
       "num_private            59400.0                       0.474141   \n",
       "region_code            59400.0                      15.297003   \n",
       "district_code          59400.0                       5.629747   \n",
       "population             59400.0                       0.333443   \n",
       "scheme_management      59400.0                       0.380589   \n",
       "permit                 59400.0                            0.0   \n",
       "construction_year      59400.0                    1997.552921   \n",
       "extraction_type_class  59400.0                       0.549158   \n",
       "payment                59400.0                       0.573266   \n",
       "water_quality          59400.0                       0.855522   \n",
       "quantity               59400.0                       0.701475   \n",
       "source                 59400.0                       0.487003   \n",
       "waterpoint_type        59400.0                       0.582912   \n",
       "recorded_year          59400.0                    2011.921667   \n",
       "\n",
       "                                       min                  25%  \\\n",
       "id                                     0.0             18519.75   \n",
       "amount_tsh                             0.0                  0.0   \n",
       "date_recorded          2002-10-14 00:00:00  2011-04-01 00:00:00   \n",
       "gps_height                             1.0                995.0   \n",
       "longitude                        29.607122            33.354079   \n",
       "latitude                         -11.64944            -8.540621   \n",
       "num_private                            0.0                  0.0   \n",
       "region_code                            1.0                  5.0   \n",
       "district_code                          0.0                  2.0   \n",
       "population                             0.0                  0.0   \n",
       "scheme_management                      0.0                  0.0   \n",
       "permit                                 0.0                  0.0   \n",
       "construction_year                   1960.0               1996.0   \n",
       "extraction_type_class                  0.0                  0.0   \n",
       "payment                                0.0                  0.0   \n",
       "water_quality                          0.0                  1.0   \n",
       "quantity                               0.0                  0.4   \n",
       "source                                 0.0                  0.0   \n",
       "waterpoint_type                        0.0                  0.0   \n",
       "recorded_year                       2002.0               2011.0   \n",
       "\n",
       "                                       50%                  75%  \\\n",
       "id                                 37061.5              55656.5   \n",
       "amount_tsh                             0.0             2.456456   \n",
       "date_recorded          2012-10-10 00:00:00  2013-02-09 00:00:00   \n",
       "gps_height                          1194.0              1319.25   \n",
       "longitude                        35.005943            37.178387   \n",
       "latitude                         -5.172704            -3.398151   \n",
       "num_private                            0.0                  0.0   \n",
       "region_code                           12.0                 17.0   \n",
       "district_code                          3.0                  5.0   \n",
       "population                             0.2                  0.6   \n",
       "scheme_management                      0.0                  1.0   \n",
       "permit                                 0.0                  0.0   \n",
       "construction_year                   1998.0               2004.0   \n",
       "extraction_type_class                  1.0                  1.0   \n",
       "payment                                1.0                  1.0   \n",
       "water_quality                          1.0                  1.0   \n",
       "quantity                               1.0                  1.0   \n",
       "source                                 0.0                  1.0   \n",
       "waterpoint_type                        1.0                  1.0   \n",
       "recorded_year                       2012.0               2013.0   \n",
       "\n",
       "                                       max           std  \n",
       "id                                 74247.0  21453.128371  \n",
       "amount_tsh                       17.898943       3.16077  \n",
       "date_recorded          2013-12-03 00:00:00           NaN  \n",
       "gps_height                          2770.0    471.186468  \n",
       "longitude                        40.345193      2.567468  \n",
       "latitude                         -0.998464      2.769401  \n",
       "num_private                         1776.0      12.23623  \n",
       "region_code                           99.0     17.587406  \n",
       "district_code                         80.0      9.633649  \n",
       "population                             1.0       0.38698  \n",
       "scheme_management                      1.0      0.485536  \n",
       "permit                                 0.0           0.0  \n",
       "construction_year                   2013.0      9.993723  \n",
       "extraction_type_class                  1.0      0.497582  \n",
       "payment                                1.0      0.494607  \n",
       "water_quality                          1.0      0.351577  \n",
       "quantity                               1.0      0.363207  \n",
       "source                                 1.0      0.499835  \n",
       "waterpoint_type                        1.0      0.493082  \n",
       "recorded_year                       2013.0      0.958758  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "32f6a276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready for piping\n"
     ]
    }
   ],
   "source": [
    "# create a class that we can pass to the pipeline\n",
    "# run this cell to initiate the function, then the pipeline *should* run smoothly\n",
    "def clean_func(df):\n",
    "    #\n",
    "    # Construction year\n",
    "    df['construction_year'] = df['construction_year'].replace(0, np.nan)\n",
    "    #Impute using region + installer\n",
    "    df['construction_year'] = df.groupby(['region', 'installer'])['construction_year'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "    #Impute using region only (for rows still missing)\n",
    "    df['construction_year'] = df.groupby('region')['construction_year'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "    #Use recorded year - 13\n",
    "    df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
    "    df['recorded_year'] = df['date_recorded'].dt.year\n",
    "    df['construction_year'] = df['construction_year'].fillna(df['recorded_year'] - 13)\n",
    "    #\n",
    "    # gps_height \n",
    "    df['gps_height'] = df['gps_height'].apply(lambda x: np.nan if x <= 0 else x)\n",
    "    # Fill using median per lga\n",
    "    df['gps_height'] = df.groupby('lga')['gps_height'].fillna(df['gps_height'].median())\n",
    "    # Fill any still missing using region median\n",
    "    df['gps_height'] = df.groupby(['region'])['gps_height'].fillna(df['gps_height'].median())\n",
    "    # Longitude and latitude\n",
    "    df['longitude'] = df['longitude'].replace(0, np.nan)\n",
    "    df['latitude'] = df['latitude'].where(df['latitude'] < -0.5, np.nan) # too close to the equator\n",
    "    for i in ['latitude','longitude']: # loop to fill by lga, region\n",
    "        df[i] = df.groupby(['lga'])[i].fillna(df[i].median())\n",
    "        df[i] = df.groupby(['region'])[i].fillna(df[i].median())\n",
    "    # population\n",
    "    # Fill population using median by district_code\n",
    "    df['population'] = df.groupby('lga')['population'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "    # Fill any still missing with median by region, then overall median\n",
    "    df['population'] = df.groupby('region')['population'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "    df['population'] = df['population'].fillna(df.population.median)\n",
    "    # Bin the outcome, see how it behaves\n",
    "    df['population'] = pd.cut(df['population'], [-1,1,25,90,160,260,9999999], labels=[0,0.2,0.3,0.4,0.6,1])\n",
    "    df['population'] = df['population'].astype(float)\n",
    "    #\n",
    "    # amount_tsh\n",
    "    df['amount_tsh'] = df['amount_tsh'].apply(lambda x: min(x, 15000))\n",
    "    df['amount_tsh'] = df['amount_tsh'].apply(lambda x: np.power(x,0.3))\n",
    "        ### Encode categorical variables\n",
    "    # Encode 'quantity' (and typo fix: 'insufficent' -> 'insufficient')\n",
    "    df['quantity'] = df['quantity'].replace({\n",
    "        'enough': 1,\n",
    "        'seasonal': 0.6,\n",
    "        'insufficient': 0.4,\n",
    "        'dry': 0,\n",
    "        'unknown': 0\n",
    "    })\n",
    "    df.quantity = pd.to_numeric(df.quantity, errors='coerce')\n",
    "\n",
    "    # Encode 'water_quality' as binary: good = 1, else 0\n",
    "    df['water_quality'] = np.where(df['water_quality'] == 'soft', 1, 0)\n",
    "    # Encode 'waterpoint_type' (1 = preferred type, 0 = everything else)\n",
    "    preferred_waterpoint = ['communal standpipe multiple', 'communal standpipe']\n",
    "    df['waterpoint_type'] = df['waterpoint_type'].apply(lambda x: 1 if x in preferred_waterpoint else 0)\n",
    "    # Encode 'permit' as binary: True = 1, False, missing = 0\n",
    "    df['permit'] = np.where(df['permit'] == 'True', 1, 0)\n",
    "    # Encode 'payment' as binary: never pay = 0, else = 1\n",
    "    df['payment'] = np.where(df['payment'] == 'never pay', 0, 1)\n",
    "    # Encode 'source' (1 = preferred sources, 0 = everything else)\n",
    "    preferred_sources = ['spring', 'river', 'rainwater harvesting']\n",
    "    df['source'] = df['source'].apply(lambda x: 1 if x in preferred_sources else 0)\n",
    "    # Encode 'payment' as binary: never pay = 0, else = 1\n",
    "    df['extraction_type_class'] = np.where(df['extraction_type_class'] == 'gravity', 0, 1)\n",
    "    # Encode 'scheme_management' (1 = VWC, others 0)\n",
    "    df['scheme_management'] = np.where(df['scheme_management'] == 'VWC', 0, 1)\n",
    "    # one hot encoder for basin \n",
    "    df = pd.get_dummies(data=df, columns=['basin'], drop_first=True, dtype=int)\n",
    "    ### Select what's good\n",
    "     #  Drop other columns and only keep these:\n",
    "    # df_small = df[['amount_tsh',\n",
    "    #     'gps_height',\n",
    "    #     'population',\n",
    "    #     'construction_year',\n",
    "    #     'extraction_type_class',\n",
    "    #     'payment',\n",
    "    #     'water_quality',\n",
    "    #     'quantity',\n",
    "    #     'source',\n",
    "    #     'waterpoint_type'\n",
    "    #    ]]\n",
    "    #  #  Drop other columns and only keep these:\n",
    "    # df_medium = df[['amount_tsh',\n",
    "    #          'gps_height',\n",
    "    #          'longitude',\n",
    "    #          'latitude',\n",
    "    #          'population',\n",
    "    #          'construction_year',\n",
    "    #          'extraction_type_class',\n",
    "    #          'payment',\n",
    "    #         'water_quality',\n",
    "    #         'quantity',\n",
    "    #         'source',\n",
    "    #         'waterpoint_type',, 'basin_Lake Nyasa', 'basin_Lake Rukwa',\n",
    "    #         'basin_Lake Tanganyika', 'basin_Lake Victoria', 'basin_Pangani',\n",
    "    #         'basin_Rufiji', 'basin_Ruvuma / Southern Coast', 'basin_Wami / Ruvu'\n",
    "    #         'scheme_management'\n",
    "    #        ]]\n",
    "    df = df[['amount_tsh',\n",
    "             'gps_height',\n",
    "             'longitude',\n",
    "             'latitude',\n",
    "             'population',\n",
    "             'construction_year',\n",
    "             'extraction_type_class',\n",
    "             'payment',\n",
    "            'water_quality',\n",
    "            'quantity',\n",
    "            'source',\n",
    "            'waterpoint_type', \n",
    "            'scheme_management', 'basin_Lake Nyasa', 'basin_Lake Rukwa',\n",
    "            'basin_Lake Tanganyika', 'basin_Lake Victoria', 'basin_Pangani',\n",
    "            'basin_Rufiji', 'basin_Ruvuma / Southern Coast', 'basin_Wami / Ruvu'\n",
    "           ]]\n",
    "    df['tshXpayment'] = df.amount_tsh * df.payment\n",
    "    df['extractXsource'] = df.extraction_type_class * df.source\n",
    "    df['popXtsh'] = df.population * df.amount_tsh\n",
    "    df['popXquant'] = df.population * df.quantity\n",
    "    df['popXsource'] = df.population * df.source\n",
    "    df['extractXheight'] = df.extraction_type_class * df.gps_height\n",
    "    df['typeXsource'] = df.waterpoint_type * df.source\n",
    "    df['typeXyear'] = df.waterpoint_type * df.construction_year\n",
    "    df['yearXpop'] = df.construction_year * df.population\n",
    "    df['quantXsource'] = df.quantity * df.source\n",
    "    df['yearsq'] = np.sqrt(df.construction_year + 1)\n",
    "    df_large = df\n",
    "    return df#_small, df_medium, df_large\n",
    "\n",
    "#def clean_data(self, df): \n",
    "#    df = self.clean_numeric(df) \n",
    "#    df = self.clean_categorical(df)\n",
    "#    df = self.selection(df)\n",
    "#    return df\n",
    "\n",
    "print('ready for piping')\n",
    "\n",
    "my_transformer = FunctionTransformer(clean_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b3495800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "f617343e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'named_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[310]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     23\u001b[39m param_grid = {\n\u001b[32m     24\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlogreg__C\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.01\u001b[39m, \u001b[32m0.1\u001b[39m,\u001b[32m0.5\u001b[39m,\u001b[32m1\u001b[39m],\n\u001b[32m     25\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlogreg__penalty\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33ml1\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33ml2\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     26\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlogreg__solver\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33msaga\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     27\u001b[39m }\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Grid search\u001b[39;00m\n\u001b[32m     30\u001b[39m grid_search = GridSearchCV(pipeline, param_grid, cv=\u001b[32m2\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m             betta = \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnamed_steps\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mlogreg\u001b[39m\u001b[33m'\u001b[39m].coef_)\n\u001b[32m     32\u001b[39m grid_search.fit(X_train, y_train)  \u001b[38;5;66;03m# this is essential\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Check best_estimator_\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'GridSearchCV' object has no attribute 'named_steps'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# data_transformer = FunctionTransformer(cleaner.clean_data)\n",
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(labels['status_group']) \n",
    "X = train\n",
    "\n",
    "# Define features and target \n",
    "y = y_encoded\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('data_transformer', my_transformer), # this is how we clean the data\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('logreg', LogisticRegression(max_iter=700)) \n",
    "])\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'logreg__C': [0.01, 0.1,0.5,1],\n",
    "    'logreg__penalty': ['l1','l2'],\n",
    "    'logreg__solver': ['saga']\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=2, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)  # this is essential\n",
    "\n",
    "# Check best_estimator_\n",
    "print(\" Type:\", type(grid_search))\n",
    "print(\" Best Estimator:\", grid_search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7b2e91ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Classification Report on Test Set:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.67      0.81      0.74      6452\n",
      "functional needs repair       0.00      0.00      0.00       863\n",
      "         non functional       0.64      0.57      0.60      4565\n",
      "\n",
      "               accuracy                           0.66     11880\n",
      "              macro avg       0.44      0.46      0.45     11880\n",
      "           weighted avg       0.61      0.66      0.63     11880\n",
      "\n",
      " Confusion Matrix:\n",
      "[[5235    0 1217]\n",
      " [ 591    0  272]\n",
      " [1960    0 2605]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jim/coding/water_pumps/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jim/coding/water_pumps/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jim/coding/water_pumps/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\" Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=le.classes_))\n",
    "\n",
    "print(\" Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "1c77f233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=2,\n",
      "             estimator=Pipeline(steps=[('data_transformer',\n",
      "                                        FunctionTransformer(func=<function clean_func at 0x7e97d45ce340>)),\n",
      "                                       ('scaler', StandardScaler()),\n",
      "                                       ('logreg',\n",
      "                                        LogisticRegression(max_iter=700))]),\n",
      "             param_grid={'logreg__C': [0.01, 0.1], 'logreg__penalty': ['l2'],\n",
      "                         'logreg__solver': ['lbfgs', 'saga']},\n",
      "             scoring='accuracy')\n"
     ]
    }
   ],
   "source": [
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d1c370ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/water_pumps/venv/lib/python3.12/site-packages/sklearn/pipeline.py:401\u001b[39m, in \u001b[36mPipeline.__getitem__\u001b[39m\u001b[34m(self, ind)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     name, est = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Not an int, try get step by name\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[316]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m classifier_coef = \u001b[43mpipeline\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbest_estimator_\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.coef_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/water_pumps/venv/lib/python3.12/site-packages/sklearn/pipeline.py:404\u001b[39m, in \u001b[36mPipeline.__getitem__\u001b[39m\u001b[34m(self, ind)\u001b[39m\n\u001b[32m    401\u001b[39m     name, est = \u001b[38;5;28mself\u001b[39m.steps[ind]\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Not an int, try get step by name\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnamed_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m est\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/water_pumps/venv/lib/python3.12/site-packages/sklearn/utils/_bunch.py:42\u001b[39m, in \u001b[36mBunch.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m.get(\u001b[33m\"\u001b[39m\u001b[33m_deprecated_key_to_warnings\u001b[39m\u001b[33m\"\u001b[39m, {}):\n\u001b[32m     38\u001b[39m     warnings.warn(\n\u001b[32m     39\u001b[39m         \u001b[38;5;28mself\u001b[39m._deprecated_key_to_warnings[key],\n\u001b[32m     40\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m     41\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyError\u001b[39m: 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "classifier_coef = pipeline['best_estimator_'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f851515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbbba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c81151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b6634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "myenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
